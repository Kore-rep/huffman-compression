/*
 * This Java source file was generated by the Gradle 'init' task.
 */
package huffman.compression;

import java.io.IOException;
import java.nio.file.FileAlreadyExistsException;
import java.nio.file.Files;
import java.nio.file.Paths;
import java.util.HashMap;
import java.util.Iterator;
import java.util.Map;
import java.util.PriorityQueue;
import java.util.Map.Entry;
import java.util.stream.Collector;
import java.util.stream.Collectors;
import java.util.stream.Stream;
import java.io.File;
import java.io.FileWriter;

import huffman.compression.HuffTree.HuffInternalNode;
import huffman.compression.HuffTree.HuffLeafNode;
import huffman.compression.HuffTree.HuffTree;
import huffman.compression.interfaces.HuffBaseNode;

public class Compressor {

    public static final String HEADER_DELIMITER = "!H-H!\n";

    public static void main(String[] args) {
    }

    public static void encode(String inFilePath, String outFilePath) {
        if (!inFilePath.endsWith(".txt"))
            throw new UnsupportedOperationException("Only supports text files.");
        try {
            HashMap<Character, Integer> charFreqs = calculateCharacterFrequencies(inFilePath);
            PriorityQueue<HuffTree> queue = buildPriorityQueue(charFreqs);
            HuffTree bintree = buildBinaryTree(queue);
            HashMap<Character, String> prefixTable = buildPrefixCodeTable(bintree);
            writeHeaderToFile(prefixTable, new File(outFilePath));
            writeContentsToFile(prefixTable, inFilePath, outFilePath);
        } catch (IOException e) {
            e.printStackTrace();
            System.exit(1);
        }
    }

    public static void decode(String inFilePath, String outFilePath) throws IOException {
        try (FileWriter writer = new FileWriter(outFilePath)) {
            StringBuilder mappingString = new StringBuilder();
            StringBuilder outString = new StringBuilder();
            try (Stream<String> lines = Files.lines(Paths.get(inFilePath))) {
                Iterator<String> it = lines.iterator();
                HashMap<String, Character> mapping = new HashMap<>();
                if (it.next().equals(HEADER_DELIMITER.trim())) {
                    String hashMapString = it.next();
                    mapping = constructMap(hashMapString);
                    if (!it.next().equals(HEADER_DELIMITER.trim())) {
                        throw new IOException("File header is not in the correct format");
                    }
                } else {
                    throw new IOException("File header is not in the correct format");
                }
                while (it.hasNext()) {
                    String line = it.next();
                    // Consumer header and construct map

                    for (int i = 0; i < line.chars().count(); i++) {
                        mappingString.append(line.charAt(i));
                        if (mapping.containsKey(mappingString.toString())) {
                            outString.append(mapping.get(mappingString.toString()));
                            mappingString.setLength(0);
                        }
                    }
                    writer.append(outString.toString());
                    outString.setLength(0);
                }
            }
        }
    }

    // {00=a, 11=e, 100=c, 101=f, 0110=b, 0111=d, 010=g}
    public static HashMap<String, Character> constructMap(String mapString) {
        HashMap<String, Character> outMap = new HashMap<>();
        String[] pairs = mapString.substring(1, mapString.length() - 1).split(",");
        for (String pair : pairs) {
            String[] kV = pair.split("=");
            outMap.put(kV[0].trim(), kV[1].charAt(0));
        }
        return outMap;

    }

    public static HashMap<Character, Integer> calculateCharacterFrequencies(String filePath) throws IOException {
        HashMap<Character, Integer> map = new HashMap<>();
        try (Stream<String> lines = Files.lines(Paths.get(filePath))) {
            lines.forEach(line -> {
                line.chars().forEach(c -> {
                    map.put((char) c, map.getOrDefault((char) c, 0) + 1);
                });

            });
        }
        return map;
    }

    public static PriorityQueue<HuffTree> buildPriorityQueue(Map<Character, Integer> map) {
        PriorityQueue<HuffTree> heap = new PriorityQueue<>();
        map.entrySet().forEach(entry -> {
            heap.add(new HuffTree(entry.getKey(), entry.getValue()));
        });
        return heap;
    }

    public static HuffTree buildBinaryTree(PriorityQueue<HuffTree> heap) {
        HuffTree tmp1, tmp2, tree = null;

        while (heap.size() > 1) {
            tmp1 = heap.poll();
            tmp2 = heap.poll();
            tree = new HuffTree(tmp1.root(), tmp2.root(), tmp1.weight() + tmp2.weight());
            heap.add(tree);
        }
        return tree;
    }

    public static HashMap<Character, String> buildPrefixCodeTable(HuffTree tree) {
        HashMap<Character, String> prefixTable = new HashMap<>();
        preOrderTraversal(tree.root(), prefixTable, "");
        return prefixTable;
    }

    public static void preOrderTraversal(HuffBaseNode root, HashMap<Character, String> map, String code) {

        HuffBaseNode node = root;
        if (root.isLeaf()) {
            map.put(((HuffLeafNode) node).value(), code);
            return;
        }
        preOrderTraversal(((HuffInternalNode) root).left(), map, code + "0");
        preOrderTraversal(((HuffInternalNode) root).right(), map, code + "1");
    }

    // Can either write frequency table or graph
    // Have chosen to go with frequency table as it should be easier to reconstruct
    // Invert map when storing for easier reconstruction of data
    public static void writeHeaderToFile(HashMap<Character, String> map, File f) throws IOException {
        Map<String, Character> invertedMap = invertMap(map);
        if (f.createNewFile()) {
            try (FileWriter writer = new FileWriter(f)) {
                writer.append(HEADER_DELIMITER);
                writer.append(invertedMap.toString() + '\n');
                writer.append(HEADER_DELIMITER);
            }
        } else {
            throw new FileAlreadyExistsException(f.getName());
        }
    }

    // Only use with guaranteed unique mappings (as in this case)
    public static <V, K> Map<V, K> invertMap(Map<K, V> map) {
        return map.entrySet()
                .stream()
                .collect(Collectors.toMap(Entry::getValue, Entry::getKey));
    }

    public static void writeContentsToFile(HashMap<Character, String> map, String inFilePath, String outFilePath)
            throws IOException {
        try (FileWriter writer = new FileWriter(outFilePath, true)) {
            StringBuilder lineBuilder = new StringBuilder();
            try (Stream<String> lines = Files.lines(Paths.get(inFilePath))) {
                lines.forEach(line -> {

                    line.chars().forEach(c -> {
                        lineBuilder.append(map.get((char) c));
                    });
                    try {
                        writer.append(lineBuilder.toString());
                    } catch (IOException e) {
                    }

                    lineBuilder.setLength(0);
                });
            }
        }
    }
}
